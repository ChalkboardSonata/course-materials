---
title: "Principle Component Analysis"
output:
  xaringan::moon_reader:
    css: [fc, fc-fonts, reed.css, default]
    lib_dir: libs
    nature:
      highlightStyle: atelier-forest-light
      highlightLines: true
      highlightSpans: true
      countIncrementalSlides: false
---

```{r echo = FALSE, warning=FALSE, message=FALSE}
library(knitr)
opts_chunk$set(warning = FALSE, message = FALSE)
```


# A professional nose
--

```{r out.width=650, out.height=370, echo = FALSE, fig.align='center'}
knitr::include_graphics("figs/smell-guy.jpeg")
```


---
# Ex: Fine fragrance
--

```{r echo = FALSE}
experts <- read.table(file = "../../data/perfumes.csv", header = TRUE, sep = ",",
                      dec = ".", quote= "\"")

library(dplyr)
experts <- experts %>%
  filter(Session == 1) %>%
  select(-Panelist, -Session, -Rank, -Wrapping) %>%
  group_by(Product) %>%
  summarize(spicy = mean(Spicy),
            heady = mean(Heady),
            fruity = mean(Fruity),
            green = mean(Green),
            vanilla = mean(Vanilla),
            floral = mean(Floral),
            woody = mean(Woody),
            citrus = mean(Citrus),
            marine = mean(Marine),
            greedy = mean(Greedy),
            oriental = mean(Oriental))
names(experts)[1] <- "perfume"
```

- 12 experts were asked to rate 12 perfumes on 11 scent adjectives.
--

.tiny[
```{r echo = FALSE}
names(experts)[-1]
```
]

--

- Each rating is on the scale 1 - 10.
--

- Ratings for each perfume were averaged across experts.


---
class: small
# Ex: Fine fragrance, cont.

```{r head, eval = FALSE}
head(experts)
```

--

```{r ref.label = "head", echo = FALSE}
head(experts)
```


---
# Learning structure
--

How do we visualize this data set?
--

- Representing *all* of the structure in the data requires $p = 11$ dimensions.

$$ {11 \choose 2} = 55 \textrm{ possible scatterplots}$$ 
--

- Can we represent *most* of the structure using fewer dimensions?


---
# A particularly useful scatterplot
--

```{r echo = FALSE, fig.height=6.5, fig.width = 6.5, fig.align='center'}
pca1 <- prcomp(experts[, -1], scale = TRUE)

library(ggplot2)
library(ggrepel)
d <- as.data.frame(pca1$x)
d$perfume <- experts$perfume
levels(d$perfume)[levels(d$perfume)=="Cin\xe9ma"] <- "Cinema"
p1 <- ggplot(d, aes(x = PC1, y = PC2)) +
  geom_point(size = 3) +
  geom_text_repel(aes(label = perfume)) +
  xlim(c(-5, 5)) +
  theme_bw(base_size = 18)
p1
```


---
# Principle Component Analysis (PCA)
--

Produces a low-dimensional representation of a dataset. It finds a sequence of linear combinations of the variables that have maximal variance and are mutually uncorrelated.

--


Used to:

- Visualize structure in data
- Learn about latent meta-variables
- Produce imputs for subsequent supervised learning

---
boardwork


---
# Dimension Reduction
--

Reducing from $p = 3$ to 2 principal components.

```{r out.width=770, out.height=370, echo = FALSE, fig.align='center'}
knitr::include_graphics("figs/pca-3-2.png")
```


---
# Finding PCs
--

For each component, we want the $\phi$ vector that solves the optimization problem:

$$\textrm{max} \left(\frac{1}{n} \sum_{i = 1}^n z_{i1}^2 \right) \textrm{ subject to } \sum_{j = 1}^p \phi_{j1}^2 = 1$$

where each $z_{i1} = \sum_{j = 1}^p \phi_{j1}x_{ij}$.

Can be solved via an eigen decomposition ( $z_i$: eigenvectors of the covariance matrix of $X$).

---
# Interpretation
--

The weights corresponding to a PC, $\phi_{j1}$, are called the *loadings*.
--

#### What does PC1 represent?

.tiny[
```{r echo = FALSE}
pca1$rotation[, 1]
```
]

--

Bright vs Dark?

---
# Interpretation
--

#### What does PC2 represent?

.tiny[
```{r echo = FALSE}
pca1$rotation[, 2]
```
]

--

Mellow vs piquant?


---
# Biplot
--

```{r echo = FALSE, fig.align="center", fig.height = 7, fig.width=7}
biplot(pca1)
```


---
# Ex. More Crime
--

This data set contains statistics, in arrests per 100,000 residents for assault, murder, and rape in each of the 50 US states in 1973. Also given is the percent of the population living in urban areas.

```{r}
head(USArrests)
```


---
# PCA
--

```{r}
pca1 <- prcomp(USArrests, scale = TRUE)
names(pca1)
```

--

- `rotation` holds the matrix of loadings; the $\phi$'s.
- `x` holds the scores for the principle components; the $z_{ij}$.

--

```{r}
pca1$rotation
```


---
# A particularly useful scatterplot
--

```{r echo = FALSE, fig.height=6.5, fig.width = 6.5, fig.align='center'}
d <- as.data.frame(pca1$x)
d$state <- row.names(d)

p1 <- ggplot(d, aes(x = PC1, y = PC2)) +
  geom_point(size = 3) +
  geom_text_repel(aes(label = state)) +
  xlim(c(-3, 3)) +
  theme_bw(base_size = 18)
p1
```


---
# Interpretation
--

```{r}
pca1$rotation
```

--

- PC1: crime
- PC2: urbanization


---
# Biplot
--

```{r fig.height = 5.7, fig.width=5.7, fig.align="center"}
biplot(pca1)
```


---
# Constructing a scree plot
--

Used to visualize the proportion of variance explained (PVE) by each PC.

--

```{r eval = FALSE}
d <- data.frame(PC = 1:4,
                PVE = pca1$sdev^2 /
                  sum(pca1$sdev^2))
ggplot(d, aes(x = PC, y = PVE)) +
  geom_line() + 
  geom_point()
```


---
# Scree plot
--

```{r echo = FALSE, fig.align="center", fig.height = 5.5, fig.width=7}
d <- data.frame(PC = 1:4,
                PVE = pca1$sdev^2 / sum(pca1$sdev^2))
ggplot(d, aes(x = PC, y = PVE)) +
  geom_line() + 
  geom_point() +
  theme_bw(base_size = 18)
```


---
# How many PCs?
--

- 1st PC: 62% PVE
- 1st + 2nd PC: 62 + 25 = 87% PVE

Usually most of the structure is in the first several principal components, but results may vary!

*Rule of thumb*: look for the elbow in the scree plot.

