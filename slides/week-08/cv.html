<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Resampling Methods</title>
    <meta charset="utf-8" />
    <link href="libs/remark-css-0.0.1/fc.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/fc-fonts.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="reed.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Resampling Methods

---

# Resampling

Def: *Draw many samples from the training data and refit the model to each in order to learn about your model.*


---
# Cross-Validation
--

Methods to estimate the test error rate (MSE, misclassification error) by

- holding out a subset of the training data from the fitting process
- using that model to predict on the subset

--

## Three Flavors

1. Validation Set
--

2. Leave-one-out
--

3. `\(k\)`-fold


---
# Validation Set

--

1. Randomly split data into a *training set* and a *validation set*.
--

2. Fit model to *training set*.
--

3. Use model to predict responses for *validation set*.
--

4. Compute validation set error rate as estimate of test error rate.
--


Let's look back on how we compared Logistic Regression to LDA . . .


---
# Split data into training/validation
--


```r
library(ISLR)
data(Default)
set.seed(391)
test_ind &lt;- sample(1:10000, size = 5000)
Default_test &lt;- Default[test_ind, ]
Default_train &lt;- Default[-test_ind, ]
```


---
# Fit models to train
--


```r
# Logistic
m1 &lt;- glm(default ~ balance, 
          data = Default_train, 
          family = binomial)

# LDA
library(dplyr)
est &lt;- Default_train %&gt;%
  group_by(default) %&gt;%
  summarize(n = n(),
            prop = n/nrow(Default_train),
            mu = mean(balance),
            ssx = var(balance) * (n - 1))
```

---
# Fit models to train, cont.
--

Pull off estimates (and convert class).


```r
pi_n &lt;- as.numeric(est[1, 3])
pi_y &lt;- as.numeric(est[2, 3])
mu_n &lt;- as.numeric(est[1, 4])
mu_y &lt;- as.numeric(est[2, 4])
sig_sq &lt;- (1/(nrow(Default_train) - 2)) *
  sum(est$ssx)
```


---
# Make predictions on validation
--


```r
log_pred &lt;- predict(m1, 
                    newdata = Default_test, 
                    type = "response")

my_lda &lt;- function(x, pi, mu, sig_sq) {
  x * (mu/sig_sq) - (mu^2)/(2 * sig_sq) + log(pi)
}

d_n &lt;- my_lda(Default_test$balance, 
              pi_n, 
              mu_n, 
              sig_sq)
d_y &lt;- my_lda(Default_test$balance,
              pi_y, 
              mu_y,
              sig_sq)

my_log_pred &lt;- ifelse(log_pred &lt; 0.5, "No","Yes")
my_lda_pred &lt;- ifelse(d_n &gt; d_y, "No", "Yes")
```


---
# Misclassification Rates
--


```r
conf_log &lt;- table(my_log_pred, 
                  Default_test$default)
conf_lda &lt;- table(my_lda_pred, 
                  Default_test$default)
(conf_log[2, 1] + conf_log[1, 2])/
  nrow(Default_test)
```

```
## [1] 0.0238
```

```r
 (conf_lda[2, 1] + conf_lda[1, 2])/
  nrow(Default_test)
```

```
## [1] 0.0244
```

**Logistic has the lower test error rate**.


---
# Let's do that again
--

How would have our conclusions changed if we had used a different partition into training and validation sets?

--

.tiny[

```r
test_ind &lt;- sample(1:10000, size = 5000)
Default_test &lt;- Default[test_ind, ]
Default_train &lt;- Default[-test_ind, ]
```
]

(Re-run all that code)



.tiny[

```r
(conf_log[2, 1] + conf_log[1, 2])/
  nrow(Default_test)
```

```
## [1] 0.0294
```

```r
 (conf_lda[2, 1] + conf_lda[1, 2])/
  nrow(Default_test)
```

```
## [1] 0.0298
```
]

---
# Let's do that many times
--

&lt;img src="cv_files/figure-html/unnamed-chunk-9-1.png" style="display: block; margin: auto;" /&gt;

---

&lt;img src="cv_files/figure-html/unnamed-chunk-10-1.png" style="display: block; margin: auto;" /&gt;

---

&lt;img src="cv_files/figure-html/unnamed-chunk-11-1.png" style="display: block; margin: auto;" /&gt;


---
# Validation Set
--

### Downsides

1. Estimate of test error rate can be highly variable based on the partition.
2. You only use a fraction of the data to fit the model &gt; overestimating test error rate.


---
# Leave-one-out
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "atelier-forest-light",
"highlightLines": true,
"highlightSpans": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
