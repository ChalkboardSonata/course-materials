---
title: "Extending Linear Discriminant Analysis"
output:
  xaringan::moon_reader:
    css: ["fc", "fc-fonts", "reed.css", "default"]
    lib_dir: libs
    nature:
      highlightStyle: atelier-forest-light
      highlightLines: true
      highlightSpans: true
      countIncrementalSlides: false
---

```{r echo = FALSE}
library(knitr)
opts_chunk$set(warning = FALSE, message = FALSE, fig.align = "center")
```

```{r echo = FALSE}
library(ISLR)
m1 <- glm(default ~ balance, data = Default, family = binomial)
my_log_pred <- ifelse(m1$fit < 0.5, "No", "Yes")
conf_log <- table(my_log_pred, Default$default)
```

# Types of Errors

Let's say you work for a bank and you're tasked with building a model that will
predict whether someone will default given their credit history (i.e. balance).

--

What could go wrong?

```{r}
conf_log
```

--

1. Deny credit to someone who would not have defaulted (false positive)
2. Give credit to somone who will default (false negative)


---

What could we change to lower our false positive rate?

```{r cm1, eval = FALSE}
my_log_pred <- ifelse(m1$fit < 0.6, "No", "Yes")
conf_log_6 <- table(my_log_pred, Default$default)
conf_log_6
```

--

```{r ref.label = "cm1", echo = FALSE}
my_log_pred <- ifelse(m1$fit < 0.6, "No", "Yes")
conf_log_6 <- table(my_log_pred, Default$default)
conf_log_6
```

--

```{r}
conf_log
```



---

And if we raise the threshold a bit more?

--

```{r cm2, eval = FALSE}
my_log_pred <- ifelse(m1$fit < 0.7, "No", "Yes")
conf_log_7 <- table(my_log_pred, Default$default)
conf_log_7
```

--

```{r ref.label = "cm2", echo = FALSE}
my_log_pred <- ifelse(m1$fit < 0.7, "No", "Yes")
conf_log_7 <- table(my_log_pred, Default$default)
conf_log_7
```

--

```{r}
conf_log_6
```



---
# False positive rate

--

Of all of the actual negatives, how many did we declare positive?

--

$$
FPR = FP / (FP + TN)
$$

--

.tiny[
```{r}
thresh <- c(0.5, 0.6, 0.7)
FPR <- c(conf_log["Yes", "No"]/sum(conf_log[, "No"]),
        conf_log_6["Yes", "No"]/sum(conf_log_6[, "No"]),
        conf_log_7["Yes", "No"]/sum(conf_log_7[, "No"]))
FPR
```
]

---
# True positive rate

--

Of all of the actual positives, how many did we declare positive?

--

$$
TPR = TP / (TP + FN)
$$

--

.tiny[
```{r}
thresh <- c(0.5, 0.6, 0.7)
TPR <- c(conf_log["Yes", "Yes"]/sum(conf_log[, "Yes"]),
        conf_log_6["Yes", "Yes"]/sum(conf_log_6[, "Yes"]),
        conf_log_7["Yes", "Yes"]/sum(conf_log_7[, "Yes"]))
TPR
```
]

---
# ROC curve

```{r, fig.height=7, fig.width = 7, echo = FALSE, fig.align="center"}
# ROC function
library(ggplot2)
plotROC <- function(model, nthresh = 1000) {
  k <- seq(0, 1, length.out = nthresh)
  TPR <- rep(NA, nthresh)
  FPR <- rep(NA, nthresh)
  for(i in 1:nthresh) {
    pred <- as.factor(ifelse(model$fit < k[i], "No", "Yes"))
    if (levels(pred) == "Yes") {levels(pred) <- c("Yes", "No")}
    if (levels(pred) == "No") {levels(pred) <- c("No", "Yes")}
    conf <- table(pred, Default$default)
    TPR[i] <- conf["Yes", "Yes"]/ sum(conf[, "Yes"])
    FPR[i] <- conf["Yes", "No"]/ sum(conf[, "No"])
  }
  df <- data.frame(TPR, FPR)
  ggplot(df, aes(x = FPR, y = TPR)) +
    geom_line(col = "forestgreen", lwd = 1.3) +
    xlab("False Positive Rate") +
    ylab("True Positive Rate") +
    theme_bw()
}

plotROC(m1)
```


---

---
# LDA with p > 1, K > 2

--

<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Iris_versicolor_3.jpg/1920px-Iris_versicolor_3.jpg" alt="Iris" width="304" height="228">

--

.tiny[
```{r}
head(iris)
```
]

---
# Fisher's Irises

```{r echo = FALSE, fig.width = 8, fig.height = 7, fig.align = "center"}
library(ggplot2)

p1 <- ggplot(iris, aes(x = Sepal.Length, 
                       y = Sepal.Width,
                       color = Species)) + 
  geom_point(size = 3) +
  theme_bw()

p1
```


---
# LDA Classification

---

Can be done quickly using the `lda()` function in the `MASS` package.

```{r lda1, eval = FALSE}
library(MASS)
mlda <- lda(Species ~ Sepal.Length + Sepal.Width,
            data = iris)
mlda_pred <- predict(mlda)
(conf_mlda <- table(mlda_pred$class, 
                    iris$Species))
```

--

```{r ref.label = "lda1", echo = FALSE}
library(MASS)
mlda <- lda(Species ~ Sepal.Length + Sepal.Width, 
            data = iris)
mlda_pred <- predict(mlda)
(conf_mlda <- table(mlda_pred$class, 
                    iris$Species))
```


---
# LDA Misclassification Rate

--

```{r}
conf_mlda
```

--

```{r mlda2, eval = FALSE}
(sum(conf_mlda) - sum(diag(conf_mlda)))/
  sum(conf_mlda)
```

--

```{r ref.label = "mlda2", echo = FALSE}
(sum(conf_mlda) - sum(diag(conf_mlda)))/
  sum(conf_mlda)
```

---
# LDA decision boundaries

--

```{r echo = FALSE, fig.width = 8, fig.height = 7, fig.align = "center"}
# credit to dean young for this plot
contour_data <- expand.grid(Sepal.Length = seq(min(iris$Sepal.Length), max(iris$Sepal.Length), length = 300),
  Sepal.Width = seq(min(iris$Sepal.Width), max(iris$Sepal.Width), length = 300))

lda_predict <- data.frame(contour_data, Species=as.numeric(predict(mlda, contour_data)$class))

p2 <- ggplot(data=iris, aes(x = Sepal.Length, y = Sepal.Width)) + 
  geom_point(aes(col=Species), size = 3) +
  stat_contour(aes(x=Sepal.Length, y=Sepal.Width, z=Species), data=lda_predict, 
               col = 1, lineend = "round") +
  theme_bw()

p2

```


---
# LDA summary

--

- Focuses on modeling the predictors: $f_k(X) = \textrm{Normal}(\mu_k, \sum)$
- Uses Bayes Rule to find the probabilities that an observation in is each class
given the probabilities of all the $\pi_k f_k(X)$.

--

**Note**

- Allows each class to have its own $\mu_k$.
- Constrains $\sum$ to be shared between the classes (inducing linear decision
boundaries).

--

*Question*

On data set with 15 predictors and 1000 observations, would you worry more about
the *bias* or the *variance* of this method?


---
# Quadratic Discriminant Analysis (QDA)

--


Focuses on modeling the predictors: $f_k(X) = \textrm{Normal}(\mu_k, \sum_k)$

--

*Allow each class to have it's own covariance matrix*


---
# QDA

--

```{r qda1, eval = FALSE}
mqda <- qda(Species ~ Sepal.Length + Sepal.Width, 
            data = iris)
mqda_pred <- predict(mqda)
(conf_mqda <- table(mqda_pred$class,
                    iris$Species))
```

--

```{r ref.label = "qda1", echo = FALSE}
mqda <- qda(Species ~ Sepal.Length + Sepal.Width,
            data = iris)
mqda_pred <- predict(mqda)
(conf_mqda <- table(mqda_pred$class,
                    iris$Species))
```

---
# QDA Misclassification Rate

--

```{r}
conf_mqda
```

--

```{r qda2, eval = FALSE}
(sum(conf_mqda) - sum(diag(conf_mqda)))/sum(conf_mqda)
```

--

```{r ref.label = "qda2", echo = FALSE}
(sum(conf_mqda) - sum(diag(conf_mqda)))/
  sum(conf_mqda)
```

---
# LDA decision boundaries

--

```{r echo = FALSE, fig.width = 8, fig.height = 7, fig.align = "center"}
# credit to dean young for this plot
qda_predict <- data.frame(contour_data, Species=as.numeric(predict(mqda, contour_data)$class))

p3 <- ggplot(data=iris, aes(x = Sepal.Length, y = Sepal.Width)) + 
  geom_point(aes(col=Species), size = 3) +
  stat_contour(aes(x=Sepal.Length, y=Sepal.Width, z=Species), data=qda_predict, col = 1) +
  theme_bw()

p3

```

